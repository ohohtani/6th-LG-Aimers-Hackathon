import numpy as np
import pandas as pd
import pickle
import optuna
from catboost import CatBoostClassifier
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold, train_test_split

# ğŸ”¹ 1. ë°ì´í„° ë¡œë“œ
file_path_train = "train3_updated.csv"
file_path_test = "test3_updated.csv"
sample_submission_path = "sample_submission.csv"

df_train = pd.read_csv(file_path_train)
df_test = pd.read_csv(file_path_test)
df_sample_submission = pd.read_csv(sample_submission_path)

# ğŸ”¹ 2. 'ID' ì»¬ëŸ¼ ìœ ì§€
test_ids = df_sample_submission["ID"]

# ğŸ”¹ 3. ë°ì´í„° ì¤€ë¹„ (íŒŒìƒ ë³€ìˆ˜ ìƒì„± í¬í•¨)
target_col = "ì„ì‹  ì„±ê³µ ì—¬ë¶€"
if target_col not in df_train.columns:
    raise ValueError(f"âŒ '{target_col}' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° í™•ì¸ í•„ìš”!")

X = df_train.drop(columns=["ID", target_col], errors="ignore")
y = df_train[target_col]
X_test = df_test.drop(columns=["ID"], errors="ignore")

# âœ… íŒŒìƒ ë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ (1ë²ˆ & 3ë²ˆ ì ìš©)
def add_derived_features(df):
    df = df.copy()
    
    # ğŸ”‘ 1ë²ˆ: ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´ ìˆ˜ì¹˜í˜• ë³€í™˜
    age_map = {
        "ë§Œ18-34ì„¸": 26, "ë§Œ35-37ì„¸": 36, "ë§Œ38-39ì„¸": 38, 
        "ë§Œ40-42ì„¸": 41, "ë§Œ43-44ì„¸": 43, "ë§Œ45-50ì„¸": 47
    }
    df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´_ìˆ˜ì¹˜'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].map(age_map)
    
    # ğŸ”‘ 3ë²ˆ: ë‚˜ì´ ì œê³± ë° ë¡œê·¸ ë³€í™˜
    df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´_ì œê³±'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´_ìˆ˜ì¹˜'] ** 2
    df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´_ë¡œê·¸'] = np.log1p(df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´_ìˆ˜ì¹˜'])

    # ê¸°ì¡´ íŒŒìƒ ë³€ìˆ˜ ìœ ì§€
    df['ì´ì‹ëœ_ë°°ì•„_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'].replace(0, np.nan)
    df['ë¯¸ì„¸ì£¼ì…_íš¨ìœ¨'] = df['ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜'] / df['ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜'].replace(0, np.nan)
    df['ë°°ì•„_í•´ë™_ì´ì‹_ì°¨ì´'] = df['ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼'] - df['ë°°ì•„ í•´ë™ ê²½ê³¼ì¼']
    df['ë¶ˆì„_ì›ì¸_í•©ê³„'] = (df['ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸'] + df['ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜'] + 
                          df['ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸'] + df['ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• '] + 
                          df['ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦'])
    trial_map = {'0íšŒ': 0, '1íšŒ': 1, '2íšŒ': 2, '3íšŒ': 3, '4íšŒ': 4, '5íšŒ': 5, '6íšŒ ì´ìƒ': 6}
    df['ì´_ì‹œìˆ _íšŸìˆ˜_ìˆ˜ì¹˜'] = df['ì´ ì‹œìˆ  íšŸìˆ˜'].map(trial_map)
    df['ì´_ì„ì‹ _íšŸìˆ˜_ìˆ˜ì¹˜'] = df['ì´ ì„ì‹  íšŸìˆ˜'].map(trial_map)
    df['ì‹œìˆ ë‹¹_ì„ì‹ _íš¨ìœ¨'] = df['ì´_ì„ì‹ _íšŸìˆ˜_ìˆ˜ì¹˜'] / df['ì´_ì‹œìˆ _íšŸìˆ˜_ìˆ˜ì¹˜'].replace(0, np.nan)
    
    # ë²”ì£¼í˜• NaN ì²˜ë¦¬
    cat_cols = df.select_dtypes(include=["object"]).columns
    df[cat_cols] = df[cat_cols].fillna('Unknown')
    
    return df

# íŒŒìƒ ë³€ìˆ˜ ì ìš©
X = add_derived_features(X)
X_test = add_derived_features(X_test)

# ğŸ”¹ 4. ë²”ì£¼í˜• ë³€ìˆ˜ í™•ì¸
cat_features = X.select_dtypes(include=["object"]).columns.tolist()

# ğŸ”¹ 5. ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰ (Optuna)
def objective(trial):
    params = {
        "iterations": trial.suggest_int("iterations", 500, 3000),
        "depth": trial.suggest_int("depth", 4, 10),
        "learning_rate": trial.suggest_loguniform("learning_rate", 0.005, 0.1),
        "l2_leaf_reg": trial.suggest_loguniform("l2_leaf_reg", 1.0, 50.0),
        "border_count": trial.suggest_int("border_count", 16, 64),
        "grow_policy": trial.suggest_categorical("grow_policy", ["SymmetricTree", "Lossguide", "Depthwise"]),
        "bootstrap_type": trial.suggest_categorical("bootstrap_type", ["Bernoulli", "Poisson", "Bayesian"]),
        "task_type": "GPU",
        "eval_metric": "AUC",
        "loss_function": "Logloss",
        "verbose": 0,
        "auto_class_weights": "Balanced"
    }
    if params["bootstrap_type"] in ["Bernoulli", "Poisson"]:
        params["subsample"] = trial.suggest_uniform("subsample", 0.7, 1.0)

    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
    auc_scores = []
    for train_idx, valid_idx in kf.split(X, y):
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]
        model = CatBoostClassifier(**params)
        model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=cat_features, 
                  early_stopping_rounds=100, verbose=0)
        valid_preds = model.predict_proba(X_valid)[:, 1]
        auc_scores.append(roc_auc_score(y_valid, valid_preds))
    return np.mean(auc_scores)

# Optuna ì‹¤í–‰ ë° ìƒˆ .pkl ì €ì¥
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)

best_params = study.best_params
best_params.update({
    "task_type": "GPU",
    "eval_metric": "AUC",
    "loss_function": "Logloss",
    "verbose": 0,
    "auto_class_weights": "Balanced"
})

new_params_save_path = "cat_self_ensemble.pkl"
with open(new_params_save_path, "wb") as f:
    pickle.dump(best_params, f)

print(f"ğŸ“ ìƒˆ ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {new_params_save_path}")
print(f"ğŸ¯ ìƒˆ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}")

# ğŸ”¹ 6. ì €ì¥ëœ íŒŒë¼ë¯¸í„° ë¶ˆëŸ¬ì˜¤ê¸°
with open(new_params_save_path, "rb") as f:
    best_params = pickle.load(f)

print(f"ğŸ“ ì €ì¥ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {new_params_save_path}")
print(f"ğŸ¯ ë¶ˆëŸ¬ì˜¨ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}")

# ğŸ”¹ 7. ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬ ë° ìµœì  random_seed íƒìƒ‰
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

seed_range = range(0, 100)
val_scores = []

for seed in seed_range:
    best_params["random_seed"] = seed
    model = CatBoostClassifier(**best_params)
    model.fit(X_train, y_train, eval_set=(X_val, y_val), cat_features=cat_features, early_stopping_rounds=100, verbose=0)
    val_preds = model.predict_proba(X_val)[:, 1]
    score = roc_auc_score(y_val, val_preds)
    val_scores.append((seed, score))
    print(f"Seed {seed} - ROC-AUC: {score:.5f}")

# ìƒìœ„ 3ê°œ ì‹œë“œ ì„ íƒ
top_seeds = sorted(val_scores, key=lambda x: x[1], reverse=True)[:3]
top_seeds = [s[0] for s in top_seeds]
print(f"ì„ íƒëœ ìƒìœ„ 3ê°œ ì‹œë“œ: {top_seeds}")

# ğŸ”¹ 8. ìƒìœ„ ì‹œë“œë¡œ ì•™ìƒë¸”
test_preds_optimal = np.zeros(len(X_test))
best_params["verbose"] = 100

for seed in top_seeds:
    best_params["random_seed"] = seed
    model = CatBoostClassifier(**best_params)
    model.fit(X, y, cat_features=cat_features, verbose=100)
    test_preds_optimal += model.predict_proba(X_test)[:, 1] / len(top_seeds)

# ğŸ”¹ 9. ì œì¶œ íŒŒì¼ ìƒì„±
df_submission = pd.DataFrame({"ID": test_ids, "probability": test_preds_optimal})
submission_file_path = "cat_self_ensemble.csv"
df_submission.to_csv(submission_file_path, index=False)

print(f"âœ… CatBoost ìµœì  ì‹œë“œ ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼ê°€ '{submission_file_path}' ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
