import numpy as np
import pandas as pd
import optuna
import pickle
from catboost import CatBoostClassifier
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
from sklearn.calibration import CalibratedClassifierCV

# ğŸ”¹ 1. ë°ì´í„° ë¡œë“œ
file_path_train = "train3_updated.csv"
file_path_test = "test3_updated.csv"
sample_submission_path = "sample_submission.csv"

df_train = pd.read_csv(file_path_train)
df_test = pd.read_csv(file_path_test)
df_sample_submission = pd.read_csv(sample_submission_path)

# ğŸ”¹ 2. 'ID' ì»¬ëŸ¼ ìœ ì§€ (sample_submissionì„ ìœ„í•´ í•„ìš”)
test_ids = df_sample_submission["ID"]

# ğŸ”¹ 3. Train ë°ì´í„° ì¤€ë¹„
target_col = "ì„ì‹  ì„±ê³µ ì—¬ë¶€"
if target_col not in df_train.columns:
    raise ValueError(f"âŒ '{target_col}' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° í™•ì¸ í•„ìš”!")

X = df_train.drop(columns=["ID", target_col], errors="ignore")
y = df_train[target_col]

# ğŸ”¹ 4. ë²”ì£¼í˜• ë³€ìˆ˜ í™•ì¸ (CatBoostì—ì„œ ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥)
cat_features = X.select_dtypes(include=["object"]).columns.tolist()

# ğŸ”¹ 5. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì • (ë¶ˆê· í˜• ë°ì´í„° ë³´ì •)
class_weights = {0: 0.2583, 1: 0.7417}  # ì‹¤íŒ¨(0) -> 0.25, ì„±ê³µ(1) -> 0.75

# ğŸ”¹ 6. Optunaë¥¼ í™œìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (K-Fold ì ìš©)
def objective(trial):
    bootstrap_type = trial.suggest_categorical("bootstrap_type", ["Poisson", "Bayesian"])
    params = {
        "iterations": trial.suggest_int("iterations", 500, 5000),
        "depth": trial.suggest_int("depth", 4, 12),
        "learning_rate": trial.suggest_loguniform("learning_rate", 0.001, 0.2),
        "l2_leaf_reg": trial.suggest_loguniform("l2_leaf_reg", 0.1, 100.0),
        "border_count": trial.suggest_int("border_count", 16, 128),
        "grow_policy": trial.suggest_categorical("grow_policy", ["SymmetricTree", "Lossguide", "Depthwise"]),
        "bootstrap_type": bootstrap_type,
        "bagging_temperature": trial.suggest_uniform("bagging_temperature", 0, 1),
        "random_strength": trial.suggest_loguniform("random_strength", 0.1, 10),
        "max_ctr_complexity": trial.suggest_int("max_ctr_complexity", 2, 8),
        "od_type": trial.suggest_categorical("od_type", ["IncToDec", "Iter"]),
        "od_wait": trial.suggest_int("od_wait", 50, 200),
        "class_weights": [class_weights[0], class_weights[1]],
        "random_seed": 42,
        "task_type": "GPU",
        "eval_metric": "AUC",
        "loss_function": "Logloss",
        "verbose": 0
    }
    if bootstrap_type == "Poisson":
        params["subsample"] = trial.suggest_uniform("subsample", 0.5, 1.0)

    # Stratified K-Fold ê²€ì¦ (15ê°œë¡œ í™•ì¥)
    kf = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)
    auc_scores = []

    for train_idx, valid_idx in kf.split(X, y):
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

        model = CatBoostClassifier(**params)
        model.fit(
            X_train, y_train,
            eval_set=(X_valid, y_valid),
            cat_features=cat_features,
            early_stopping_rounds=300,  # Early Stopping ê°•í™”
            verbose=0
        )

        valid_preds = model.predict_proba(X_valid)[:, 1]
        auc_scores.append(roc_auc_score(y_valid, valid_preds))

    return np.mean(auc_scores)

# ğŸ”¹ 7. Optuna ì‹¤í–‰ (200íšŒë¡œ í™•ì¥)
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=200)

# ğŸ”¹ 8. ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥ (`pkl` íŒŒì¼)
best_params = study.best_params
best_params["random_seed"] = 42
best_params["task_type"] = "GPU"
best_params["eval_metric"] = "AUC"
best_params["loss_function"] = "Logloss"
best_params["verbose"] = 100

if "colsample_bylevel" in best_params:
    del best_params["colsample_bylevel"]

params_save_path = "cat_knn_optimized.pkl"
with open(params_save_path, "wb") as f:
    pickle.dump(best_params, f)

print(f"ğŸ“ ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {params_save_path}")
print(f"ğŸ¯ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}")

# ğŸ”¹ 9. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„° í•™ìŠµ (ìµœëŒ€ ë°˜ë³µ)
best_params["iterations"] = 10000  # ê°•ì œë¡œ 10000ë²ˆ ë°˜ë³µ
best_params["class_weights"] = [class_weights[0], class_weights[1]]

final_model = CatBoostClassifier(**best_params)
final_model.fit(
    X, y,  # ì „ì²´ ë°ì´í„° ì‚¬ìš©
    cat_features=cat_features,
    verbose=100  # Early Stopping ì œê±°
)

# ğŸ”¹ 10. í”¼ì²˜ ì¤‘ìš”ë„ ê¸°ë°˜ ìƒìœ„ í”¼ì²˜ ì„ íƒ ë° ì¬í•™ìŠµ
feature_importance = final_model.get_feature_importance()
feature_names = X.columns
importance_df = pd.DataFrame({"feature": feature_names, "importance": feature_importance})
top_features = importance_df.sort_values("importance", ascending=False).head(20)["feature"].tolist()

# ìƒìœ„ í”¼ì²˜ë¡œ ë°ì´í„° ì¬êµ¬ì„±
X_top = X[top_features]
X_test = df_test.drop(columns=["ID"], errors="ignore")
X_test_top = X_test[top_features]

# ìƒìœ„ í”¼ì²˜ë¡œ ì¬í•™ìŠµ
final_model.fit(
    X_top, y,
    cat_features=[f for f in cat_features if f in top_features],
    verbose=100
)

# ğŸ”¹ 11. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ (ê¸°ë³¸ ì˜ˆì¸¡)
test_preds = final_model.predict_proba(X_test_top)[:, 1]

# ğŸ”¹ 12. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í›„ì²˜ë¦¬ (Sigmoid + Isotonic í‰ê· )
print("ğŸ”„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš© ì¤‘...")
kf = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)  # 15ê°œë¡œ í™•ì¥
calibrated_preds_sigmoid = np.zeros(len(X_test))
calibrated_preds_isotonic = np.zeros(len(X_test))

for train_idx, valid_idx in kf.split(X_top, y):
    X_train, X_valid = X_top.iloc[train_idx], X_top.iloc[valid_idx]
    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

    # ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ
    model = CatBoostClassifier(**best_params)
    model.fit(X_train, y_train, cat_features=[f for f in cat_features if f in top_features], verbose=0)

    # Sigmoid ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    calibrator_sigmoid = CalibratedClassifierCV(estimator=model, method='sigmoid', cv='prefit')
    calibrator_sigmoid.fit(X_valid, y_valid)
    calibrated_preds_sigmoid += calibrator_sigmoid.predict_proba(X_test_top)[:, 1] / kf.n_splits

    # Isotonic ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    calibrator_isotonic = CalibratedClassifierCV(estimator=model, method='isotonic', cv='prefit')
    calibrator_isotonic.fit(X_valid, y_valid)
    calibrated_preds_isotonic += calibrator_isotonic.predict_proba(X_test_top)[:, 1] / kf.n_splits

# ë‘ ë°©ì‹ í‰ê· 
calibrated_preds = (calibrated_preds_sigmoid + calibrated_preds_isotonic) / 2
print("âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ!")

# ğŸ”¹ 13. sample_submission í˜•ì‹ìœ¼ë¡œ ë³€í™˜
df_submission = pd.DataFrame({"ID": test_ids, "probability": calibrated_preds})

# ğŸ”¹ 14. ìµœì¢… CSV íŒŒì¼ ì €ì¥
submission_file_path = "cat_knn_optimized.csv"
df_submission.to_csv(submission_file_path, index=False)

print(f"âœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ CatBoost ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ '{submission_file_path}' ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
