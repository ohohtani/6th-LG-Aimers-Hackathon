# ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np
import pandas as pd
import optuna
import joblib
import xgboost as xgb
from catboost import CatBoostClassifier
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.preprocessing import LabelEncoder

# âœ… ì˜µíŠœë‚˜ ì¸ì ê²€ì¦ í•¨ìˆ˜
def validate_optuna_parameters():
    try:
        study = optuna.create_study(direction="maximize")
        study.optimize(lambda trial: 1.0, n_trials=1)
        print("âœ… Optuna ì„¤ì • í™•ì¸ ì™„ë£Œ: 'n_trials' ì¸ì ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    except TypeError as e:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", e)

# ğŸ”¹ 1. ë°ì´í„° ë¡œë“œ
file_path_train = "train3_updated.csv"
file_path_test = "test3_updated.csv"
sample_submission_path = "sample_submission.csv"

df_train = pd.read_csv(file_path_train)
df_test = pd.read_csv(file_path_test)
df_sample_submission = pd.read_csv(sample_submission_path)
test_ids = df_sample_submission["ID"]

# ğŸ”¹ 2. Train ë°ì´í„° ì¤€ë¹„
target_col = "ì„ì‹  ì„±ê³µ ì—¬ë¶€"
X = df_train.drop(columns=["ID", target_col], errors="ignore")
y = df_train[target_col]

# ğŸ”¹ 3. ë²”ì£¼í˜• ë° ìˆ«ìí˜• ë³€ìˆ˜ ë¶„ë¦¬
cat_features = X.select_dtypes(include=["object"]).columns.tolist()
print(f"âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ëª©ë¡: {cat_features}")

# âœ… XGBoostëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ ë¶ˆê°€ â†’ Label Encoding ì ìš©
if len(cat_features) > 0:
    print("ğŸ”” XGBoost ì²˜ë¦¬ìš© Label Encoding ì ìš© ì¤‘...")
    le = LabelEncoder()
    for col in cat_features:
        X[col] = le.fit_transform(X[col])
        df_test[col] = le.transform(df_test[col])
else:
    print("âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ì—†ìŒ. XGBoost ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”.")

X_numeric = X.select_dtypes(exclude=["object"])
X_test_numeric = df_test.select_dtypes(exclude=["object"])

# ğŸ”¹ 4. ë°ì´í„° ë¶„í•  (Train / Calibration)
X_train, X_calib, y_train, y_calib = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
X_numeric_train = X_train.select_dtypes(exclude=["object"])
X_numeric_calib = X_calib.select_dtypes(exclude=["object"])

# ğŸ”¹ 5. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë° scale_pos_weight ì„¤ì •
class_weights = {0: 0.2583, 1: 0.7417}
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
print(f"âœ… scale_pos_weight ê³„ì‚° ì™„ë£Œ: {scale_pos_weight:.4f}")

# âœ… ì˜µíŠœë‚˜ ì¸ì ê²€ì¦ ì‹¤í–‰
validate_optuna_parameters()

# ğŸ”¹ 6. ìµœì  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
cb_model = joblib.load("saved_cb_model.pkl")
xgb_model = joblib.load("saved_xgb_model.pkl")

# ğŸ”¹ 7. ì†Œí”„íŠ¸ ë³´íŒ… í™•ë¥  ì˜ˆì¸¡ (ê°€ì¤‘ì¹˜ ì ìš©: CatBoost=7, XGBoost=3)
y_pred_cb_proba = cb_model.predict_proba(X_calib)[:, 1]
y_pred_xgb_proba = xgb_model.predict_proba(X_numeric_calib)[:, 1]

# âœ… ê°€ì¤‘ì¹˜ ì ìš© ì†Œí”„íŠ¸ ë³´íŒ…
cat_weight, xgb_weight = 7, 3
total_weight = cat_weight + xgb_weight
y_pred_proba = (cat_weight * y_pred_cb_proba + xgb_weight * y_pred_xgb_proba) / total_weight
y_pred = (y_pred_proba >= 0.5).astype(int)

# ğŸ”¹ 8. ì„±ëŠ¥ í‰ê°€
auc_score = roc_auc_score(y_calib, y_pred_proba)
accuracy = accuracy_score(y_calib, y_pred)
print(f"âœ… ê°€ì¤‘ì¹˜ ì ìš© Soft Voting AUC: {auc_score:.4f}")
print(f"âœ… ê°€ì¤‘ì¹˜ ì ìš© Soft Voting Accuracy: {accuracy:.4f}")

# ğŸ”¹ 9. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ
_y_pred_cb_proba = cb_model.predict_proba(df_test)[:, 1]
_y_pred_xgb_proba = xgb_model.predict_proba(X_test_numeric)[:, 1]

ensemble_pred_proba = (cat_weight * _y_pred_cb_proba + xgb_weight * _y_pred_xgb_proba) / total_weight

df_submission = pd.DataFrame({"ID": test_ids, "probability": ensemble_pred_proba})
submission_file_path = "weighted_soft_voting_submission.csv"
df_submission.to_csv(submission_file_path, index=False)

print(f"âœ… ê°€ì¤‘ì¹˜ ì ìš© í™•ë¥  ê¸°ë°˜ ì œì¶œ íŒŒì¼ì´ '{submission_file_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
