import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

# 1ï¸âƒ£ Train ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 
file_path_train = "train_processed.csv"
df_train = pd.read_csv(file_path_train)

# ğŸ”¹ 'ID' ì»¬ëŸ¼ ì œê±° (Train)
if "ID" in df_train.columns:
    df_train.drop(columns=["ID"], inplace=True)

# 6ï¸âƒ£ Train ë°ì´í„° ì¤€ë¹„
X = df_train.drop(columns=["ì„ì‹  ì„±ê³µ ì—¬ë¶€"])
y = df_train["ì„ì‹  ì„±ê³µ ì—¬ë¶€"]

# 7ï¸âƒ£ Train ë°ì´í„° ë¶„í•  (í›ˆë ¨ 80%, ê²€ì¦ 20%)
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# 9ï¸âƒ£ Test ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„°)
file_path_test = "test_processed.csv"
df_test = pd.read_csv(file_path_test)

# ğŸ”¹ 'ID' ì»¬ëŸ¼ ì œê±° (Test)
if "ID" in df_test.columns:
    df_test.drop(columns=["ID"], inplace=True)

# ğŸ”Ÿ XGBoost ëª¨ë¸ ìƒì„± (ë…¼ë¬¸ ê¸°ë°˜ ìµœì í™” ì ìš©)
model = XGBClassifier(
    n_estimators=1000,   # íŠ¸ë¦¬ ê°œìˆ˜ ì¦ê°€ (Early Stoppingìœ¼ë¡œ ì¡°ì •)
    max_depth=5,         # íŠ¸ë¦¬ ê¹Šì´ ì¡°ì •
    learning_rate=0.03,  # Learning Rate ê°ì†Œ (Shrinkage)
    subsample=0.8,       # ë°ì´í„° ìƒ˜í”Œë§ ë¹„ìœ¨ (Bagging íš¨ê³¼)
    colsample_bytree=0.7, # Feature Sampling ë¹„ìœ¨ (Column Subsampling)
    colsample_bylevel=0.7,# ë ˆë²¨ ë‹¨ìœ„ Feature Sampling ë¹„ìœ¨
    gamma=1.5,           # Split ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” Min Loss Reduction
    min_child_weight=3,  # ê³¼ì í•© ë°©ì§€ (Leaf ë…¸ë“œê°€ ìµœì†Œ ê°€ì ¸ì•¼ í•˜ëŠ” ê°€ì¤‘ì¹˜)
    reg_lambda=10,       # L2 Regularization (Ridge)
    reg_alpha=0.5,       # L1 Regularization (Lasso)
    eval_metric="auc",  
    missing=np.nan,      # ê²°ì¸¡ê°’ ìë™ ì²˜ë¦¬
    random_state=42,
    use_label_encoder=False,
    early_stopping_rounds=30  # 30ë²ˆ ì—°ì† ê°œì„  ì—†ìœ¼ë©´ ì¢…ë£Œ
)

# ğŸ”Ÿ ëª¨ë¸ í•™ìŠµ (ê°€ì¤‘ì¹˜ ì ìš©í•˜ì—¬ ì¡°ì •ëœ Feature ë°˜ì˜)
model.fit(
    X_train, y_train,
    eval_set=[(X_valid, y_valid)],
    verbose=100
)

# ğŸ”Ÿ ê²€ì¦ ë°ì´í„° í‰ê°€ (ROC-AUC)
y_valid_pred = model.predict_proba(X_valid)[:, 1]  
roc_auc = roc_auc_score(y_valid, y_valid_pred)
print(f"ğŸ¯ XGBoost ê²€ì¦ ë°ì´í„° ROC-AUC: {roc_auc:.4f}")

# 1ï¸âƒ£1ï¸âƒ£ Test ë°ì´í„° ì˜ˆì¸¡ (í™•ë¥ ê°’ ì €ì¥)
y_pred_test_proba = model.predict_proba(df_test)[:, 1]
y_pred_test_proba = np.round(y_pred_test_proba, 5)

# 1ï¸âƒ£2ï¸âƒ£ ì œì¶œ íŒŒì¼ ì €ì¥
file_path_submission = "sample_submission.csv"
df_submission = pd.read_csv(file_path_submission)
df_submission["probability"] = y_pred_test_proba
file_path_final_submission = "xgboost_submission_optimized.csv"
df_submission.to_csv(file_path_final_submission, index=False)

print("âœ… XGBoost ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì™„ë£Œ!")
print(f"ğŸ¯ ìµœì¢… ROC-AUC ì ìˆ˜: {roc_auc:.4f}")
print(f"ğŸ“‚ '{file_path_final_submission}' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
